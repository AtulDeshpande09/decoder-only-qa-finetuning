{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": [
    "l_-DcMUUql5_"
   ],
   "authorship_tag": "ABX9TyOE7vlSv4gtLfLzeO0ZorUy"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YPbiutaJZk0i",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156265838,
     "user_tz": -330,
     "elapsed": 13934,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"microsoft/phi-2\""
   ],
   "metadata": {
    "id": "EKdIxj4jbtdn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156265858,
     "user_tz": -330,
     "elapsed": 17,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ],
   "metadata": {
    "id": "k00587cB0KZe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156268445,
     "user_tz": -330,
     "elapsed": 2586,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350,
     "referenced_widgets": [
      "8512166135424c4690d1ab917129d95b",
      "04c74c3cb3844173a10f9ec0f330dcfa",
      "5681e46127e64329a4d0aefaec30cd0e",
      "dbd2869ab32340bfb678ab915c4e98a3",
      "75b9db642b5d4a779bc13e7a0347a649",
      "e3784242b1f04ec48e81bc3fba1e9e6e",
      "47f67827f5ea49408c6070bd0b10f0a8",
      "a864c46b316849139a1705095c9d0ef5",
      "b61a5c1876984f9eb56f32f4c7805764",
      "93087eb511314293b5b9df83942feb83",
      "8dc79a90050a4b4d99f0010ff9f3923f",
      "33495654753a4bb3a1f431643e54f4e3",
      "7d6ac60cc6174af6ae44f0b8c3237833",
      "e36847f17903480fa3215961275fef6c",
      "e31ce99df00940f186f1a0120ff3987e",
      "32af3cee847c4128bad47a4984279048",
      "c842db2dd6074a59adc1b060bd07c67b",
      "2cfd78bb7fa34b2a936c87a39c39378f",
      "a142fd51b5ae4bd597a1bdcacacd196f",
      "96ddcc43b18b4279a2cd6c4d32adbb0b",
      "d0e7d97514b54fd596ffa5f3dc8bda04",
      "dbc31cccd4c7400391009d278f225b7e",
      "91e4b560141a4de0a3c1cf72af287146",
      "eb86c6d653f44b84bbe25ed3cfe7e4cc",
      "d8a7a17d08cc44859cb2e94e8a69dcc6",
      "ea93c2a7285d4c4a943746e125514ceb",
      "a3210fb3901142d68a82996fe4ff0fa6",
      "e91ae23459784c62a8b8397205794c72",
      "c320a54c67ff4803a77674a65d6566a7",
      "e997239ce21b4298881e59507e93fba4",
      "ba633913581b41e3974ad2dcea68f400",
      "4aa5d4ebd7684b01b0f1fd6e736b9c80",
      "75002bf9edd5452bb978cf3748a786e2",
      "df95119aaa54446f8b14a5b53fcc3255",
      "497869b7750040d19692947da0af0dec",
      "73670fd268fe4e20889d54f2cca52909",
      "8d942472c0074fa7af235d7668e160b2",
      "a1dc096b70914dde975e23b000b088bd",
      "f7ffcac1cc42453d82a714aa82c7ac12",
      "6c5e1d54d86f402198f01ebfff3c378c",
      "5fe40eae17f34b17a00273d80e60e7d3",
      "0325504988994afcaf809bf5047498f1",
      "ed0741ead93d4304836f5b7f4bf93490",
      "a1b76424111246bba6dd8ec0699e7af6",
      "50696da7ba2c4e48b2d6f0405aea20a8",
      "08dbafb90d5d4f83b2918ea9af0bef1b",
      "c5a16631bf0346d6b7ba322d718d5fed",
      "4fa0fa572a75470a878920d2a1cd4fdc",
      "b12e75dfce864193a400d8ba1b95f2ba",
      "a857ddd2f49b439cbab3b4465045597a",
      "d610a20a0f2f4fc6a2fea2a9b9bd3913",
      "e2873e7dafb94d05b3f971f3b8276c1f",
      "6340db6cb46142c5be6ef8023b126cf3",
      "dea5bc8f0f654deb9c83a694509abdc2",
      "c21a99d8b20c4757ae3b06aece26e639"
     ]
    },
    "outputId": "84f103fe-85c5-4b5f-cdd4-f6fd9988bf58"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8512166135424c4690d1ab917129d95b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33495654753a4bb3a1f431643e54f4e3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91e4b560141a4de0a3c1cf72af287146"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df95119aaa54446f8b14a5b53fcc3255"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50696da7ba2c4e48b2d6f0405aea20a8"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109,
     "referenced_widgets": [
      "c999e73821a64f07881e07683b630b70",
      "fe583c25afc448e1ae25cc2e04ccedfd",
      "15177cccec49488bbd30b22c867e6eea",
      "c82b87ee84424d6a9e8c0c036b170e80",
      "9443711e38d34f5284312b2b2a2c1f2d",
      "00ef98b4ce27465b9165facf3f89ec40",
      "75c02835dfef46388b7a7b913687dbc4",
      "13bb9463d44d41598addbac8ad23ea8a",
      "07a71e21650c40ff8a8abbd775b968c0",
      "b71199465e5446f4adc80c425b515179",
      "e8ab0a787a3a43dc92a7e1075adde184",
      "a866ca1c0a924166a1e6c33a7c0ecee9",
      "328be0acd5fd400a86509ea724f4846d",
      "7baed0e65ca24f3994807673b7458949",
      "141f62ba15f6400eaf8aecca676623ef",
      "c615e539ee034d73b842759d83b1b159",
      "71af91ad680a454f8afd7894bad6b2cb",
      "216e483b0f824365af83815fcd401383",
      "6051cf980ab9484999931dadc342e218",
      "6be7556b18764038b0538f3ec4a156bf",
      "5ffbd7d608534d1e960aa1b282c3777a",
      "83f90136027c47979b4fcae5715e57ce"
     ]
    },
    "id": "qdHoz4XDbvyE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156400030,
     "user_tz": -330,
     "elapsed": 18183,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "outputId": "b67a495a-7b6f-4172-a409-661362ea6988"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/453 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c999e73821a64f07881e07683b630b70"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a866ca1c0a924166a1e6c33a7c0ecee9"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "id": "Ajz3Jzc6o9ZK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import datasets"
   ],
   "metadata": {
    "id": "nq_sT2loc7md",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156461531,
     "user_tz": -330,
     "elapsed": 1081,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset"
   ],
   "metadata": {
    "id": "dPOJIUZCd3TB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156461736,
     "user_tz": -330,
     "elapsed": 202,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"dataset.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "print(dataset[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "referenced_widgets": [
      "8f91cfe75ed3422ea3ce309773b13bc0",
      "664429c30f5241528296a0b851144fc4",
      "76ceaa70f1be44cf8b9bc390197b97e5",
      "de875582898e4d2fababd99d5a01bf98",
      "70b51813286a47fe96dd94ce591f55d3",
      "d70ab52e49454df8abea6343e96c9aa3",
      "f45c65f8aa4f49c88e9f8baf436200be",
      "3a454ba2de7c4a609184ad438de9c3fe",
      "04c1f4fdcbba44d0a3bf4f5460442549",
      "e467eb5cebd3478dbce4a7fae6d5020f",
      "56c3e4e0884142309c6fb4eed192580e"
     ]
    },
    "id": "L9o2V-TvdzcD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156461927,
     "user_tz": -330,
     "elapsed": 182,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "outputId": "984a13bf-f401-47bd-ab50-e872dce3ab22"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f91cfe75ed3422ea3ce309773b13bc0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'question': 'What is the difference between compilation and interpretation?', 'answer': 'Compilation translates source code into machine code creating an executable file. Interpretation translates and executes code line by line without an executable.'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset.train_test_split(\n",
    "    test_size = 0.1 ,\n",
    "    seed = 42\n",
    ")"
   ],
   "metadata": {
    "id": "DbVA0eyGd2Yy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156461931,
     "user_tz": -330,
     "elapsed": 1,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ],
   "metadata": {
    "id": "rDcvhGynewR1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156461979,
     "user_tz": -330,
     "elapsed": 32,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def format_qa(example):\n",
    "    prompt = f\"Q: {example['question']}\\nA:\"\n",
    "    answer = \" \" + example[\"answer\"]  # leading space helps tokenization\n",
    "    return prompt, answer\n"
   ],
   "metadata": {
    "id": "R4CH7h6Hb0Bt",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156461982,
     "user_tz": -330,
     "elapsed": 1,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_qa(example):\n",
    "    prompt, answer = format_qa(example)\n",
    "\n",
    "    prompt_ids = tokenizer(\n",
    "        prompt,\n",
    "        add_special_tokens=False\n",
    "    ).input_ids\n",
    "\n",
    "    answer_ids = tokenizer(\n",
    "        answer + tokenizer.eos_token,\n",
    "        add_special_tokens=False\n",
    "    ).input_ids\n",
    "\n",
    "    input_ids = prompt_ids + answer_ids\n",
    "\n",
    "    labels = [-100] * len(prompt_ids) + answer_ids\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels,\n",
    "        \"attention_mask\": [1] * len(input_ids)\n",
    "    }\n"
   ],
   "metadata": {
    "id": "n9co0O0ffauq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156461984,
     "user_tz": -330,
     "elapsed": 1,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_dataset_train = train_dataset.map(\n",
    "    tokenize_qa,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")"
   ],
   "metadata": {
    "id": "jFZhoe2UfdeZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156462212,
     "user_tz": -330,
     "elapsed": 226,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "95595e4617de4e308a05581277187040",
      "00b9553932ca4556b9803899bd12b445",
      "203cbfe6d6814dcbb16b07e26bcf87e0",
      "89eb62bfafff4d74aa8477c4fb218a2a",
      "5f64cbd10beb45c4b3af7b5d9b107e77",
      "f4707db8444d40a8a49073c3437caf90",
      "e858929a64284f12bc6b9172b28b2e12",
      "79459644320c4aa49397360910fc8e83",
      "e230fd2b8d9c41d4a4292061ba602fd1",
      "ac60f8fea2014476bfcfeab9b1ba3928",
      "b15ec1b395bc44b3ba86248a3db7e2dc"
     ]
    },
    "outputId": "24793e41-0945-4ff9-e682-dbbf7ef1a7bb"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95595e4617de4e308a05581277187040"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_dataset_test = test_dataset.map(\n",
    "    tokenize_qa,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")"
   ],
   "metadata": {
    "id": "8mzmAn-OhM0v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156462250,
     "user_tz": -330,
     "elapsed": 33,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "97be325e59cd485bac3714538c0687c5",
      "4fdfc91669a84778bcfdd690bcf80876",
      "a35d8553b3eb4329967285849d6ba93d",
      "79e7447e4cbd412597bda4dd2958a352",
      "baf06f94b833419d990f4b4394c15ae4",
      "ae18c62bdc5743f0b002c88ef10b12b4",
      "3f6ef2ab62384966b45c5a3f2d5bddc5",
      "5dcb4002d5e845e7b5928d8d3427d94a",
      "1032f988cbd34eeb97e1083ae715fcb6",
      "3056a69627664f4ca6a322e0b9668e8d",
      "c9a1ce1636644589b8ae0ba419012476"
     ]
    },
    "outputId": "042a21af-1765-4fce-b96a-b182fe4cbbe5"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97be325e59cd485bac3714538c0687c5"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### data collator"
   ],
   "metadata": {
    "id": "l_-DcMUUql5_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class QACollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.pad_id = tokenizer.pad_token_id\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        input_ids = [torch.tensor(x[\"input_ids\"]) for x in batch]\n",
    "        labels = [torch.tensor(x[\"labels\"]) for x in batch]\n",
    "        attention_mask = [torch.tensor(x[\"attention_mask\"]) for x in batch]\n",
    "\n",
    "        input_ids = pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.pad_id\n",
    "        )\n",
    "\n",
    "        labels = pad_sequence(\n",
    "            labels, batch_first=True, padding_value=-100\n",
    "        )\n",
    "\n",
    "        attention_mask = pad_sequence(\n",
    "            attention_mask, batch_first=True, padding_value=0\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": labels,\n",
    "            \"attention_mask\": attention_mask,\n",
    "        }\n"
   ],
   "metadata": {
    "id": "ohZAHSe2g_sS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156462294,
     "user_tz": -330,
     "elapsed": 2,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_collator = QACollator(tokenizer)"
   ],
   "metadata": {
    "id": "ntLfcBBAqqPc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156462411,
     "user_tz": -330,
     "elapsed": 7,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LORA"
   ],
   "metadata": {
    "id": "Ez_zr86yisKM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ],
   "metadata": {
    "id": "T4MLRBpphac1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156462864,
     "user_tz": -330,
     "elapsed": 451,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"dense\"\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ],
   "metadata": {
    "id": "2k1ftHjlhfEe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156462868,
     "user_tz": -330,
     "elapsed": 18,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhGJLrDXhj8v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156464285,
     "user_tz": -330,
     "elapsed": 1409,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "outputId": "baef8541-99da-4888-a057-3975e91fdc0f"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trainable params: 5,242,880 || all params: 2,784,926,720 || trainable%: 0.1883\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logging"
   ],
   "metadata": {
    "id": "nAJJn9cDnw-3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from logger import ExperimentLogger\n",
    "logger = ExperimentLogger(\"Phi-2 Experiment\")"
   ],
   "metadata": {
    "id": "ObZo-FufnlSP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156464300,
     "user_tz": -330,
     "elapsed": 2,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class LossLoggerCallback(TrainerCallback):\n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            step = state.global_step\n",
    "            for k, v in logs.items():\n",
    "                self.logger.log(f\"Step {step} | {k}: {v}\")\n"
   ],
   "metadata": {
    "id": "16Pl7ScLntsr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156464391,
     "user_tz": -330,
     "elapsed": 46,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "logger.section(\"MODEL\")\n",
    "logger.log(f\"Model name: {model_name}\")\n",
    "logger.log(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")\n",
    "logger.log(f\"Pad token: {tokenizer.pad_token}\")\n",
    "logger.log(f\"EOS token: {tokenizer.eos_token}\")\n",
    "\n",
    "logger.section(\"DATASET STATS\")\n",
    "logger.log(f\"Train size: {len(train_dataset)}\")\n",
    "logger.log(f\"Test size: {len(test_dataset)}\")\n",
    "\n",
    "def get_trainable_params_summary(model):\n",
    "    trainable = 0\n",
    "    total = 0\n",
    "    for _, p in model.named_parameters():\n",
    "        total += p.numel()\n",
    "        if p.requires_grad:\n",
    "            trainable += p.numel()\n",
    "    return trainable, total\n",
    "\n",
    "logger.section(\"LORA CONFIGURATION\")\n",
    "logger.log(str(lora_config))\n",
    "\n",
    "trainable, total = get_trainable_params_summary(model)\n",
    "logger.log(f\"Trainable parameters: {trainable:,}\")\n",
    "logger.log(f\"Total parameters: {total:,}\")\n",
    "logger.log(f\"Trainable %: {100 * trainable / total:.4f}%\")"
   ],
   "metadata": {
    "id": "ZcMCSpyRmKfk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156464395,
     "user_tz": -330,
     "elapsed": 2,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "id": "gfxDG8cNi1Og"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments"
   ],
   "metadata": {
    "id": "LvxIjypQhnB3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156464398,
     "user_tz": -330,
     "elapsed": 2,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./phi_2\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=3,\n",
    "    bf16=True,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    report_to=\"none\"\n",
    ")"
   ],
   "metadata": {
    "id": "YuLxO-55htFI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156464401,
     "user_tz": -330,
     "elapsed": 1,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "logger.section(\"TRAINING ARGUMENTS\")\n",
    "\n",
    "for k, v in training_args.to_dict().items():\n",
    "    logger.log(f\"{k}: {v}\")"
   ],
   "metadata": {
    "id": "76L9DeKP1oRk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156464411,
     "user_tz": -330,
     "elapsed": 8,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Trainer"
   ],
   "metadata": {
    "id": "93lmmLfNh0AR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156464767,
     "user_tz": -330,
     "elapsed": 354,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_train,\n",
    "    eval_dataset=tokenized_dataset_train,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[LossLoggerCallback(logger)]\n",
    ")"
   ],
   "metadata": {
    "id": "iQ872VUHh3Pk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156464964,
     "user_tz": -330,
     "elapsed": 187,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "WyD-Txwbh_3k",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156658511,
     "user_tz": -330,
     "elapsed": 193450,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "outputId": "8f0164d1-c847-437f-d9e3-12041ff396fc"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 03:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.344043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.030187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.856002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.667098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.600446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.549462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=69, training_loss=1.804689683775971, metrics={'train_runtime': 193.0677, 'train_samples_per_second': 2.797, 'train_steps_per_second': 0.357, 'total_flos': 373110742794240.0, 'train_loss': 1.804689683775971, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference"
   ],
   "metadata": {
    "id": "78QIvMotinNn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "prompt = \"Q: What is the difference between compilation and interpretation?\\nA:\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = inputs.to(model.device)\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSyWomgJiCbi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156660341,
     "user_tz": -330,
     "elapsed": 1748,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "outputId": "82778363-c642-4adb-c48a-7a60e5d60f33"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q: What is the difference between compilation and interpretation?\n",
      "A: Compilation is a process where source code is translated into machine code, while interpretation translates code at runtime.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment Log"
   ],
   "metadata": {
    "id": "6nZFTAcnnAE4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "logger.section(\"SAMPLE GENERATIONS\")\n",
    "\n",
    "test_questions = [\n",
    "    \"What is the difference between compilation and interpretation?\",\n",
    "    \"Explain the concept of polymorphism.\"\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for q in test_questions:\n",
    "    prompt = f\"Q: {q}\\nA:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    logger.log(f\"Q: {q}\")\n",
    "    logger.log(f\"OUTPUT:\\n{text}\")\n",
    "    logger.log(\"-\" * 40)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-BSgC6snLXs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156662765,
     "user_tz": -330,
     "elapsed": 2422,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "outputId": "33b2959e-1d32-4b2b-da38-655aefcd168e"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate"
   ],
   "metadata": {
    "id": "RUviRNKoHcmH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install evaluate bert-score rouge_score"
   ],
   "metadata": {
    "id": "2GR5R9pmrvAL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156670316,
     "user_tz": -330,
     "elapsed": 7472,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0aa94c89-1467-4d11-c71f-be3c439d5549"
   },
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (1.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (26.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.9.0+cu128)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from bert-score) (5.0.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2026.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.0.0->bert-score) (3.5.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=3.0.0->bert-score) (0.7.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.3.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.3)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=ede94d17049ebe5aff54966178873881215f29f00aa2535dc298bad214508486\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score, evaluate, bert-score\n",
      "Successfully installed bert-score-0.3.13 evaluate-0.4.6 rouge_score-0.1.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "from bert_score import score\n",
    "\n",
    "def generate_answers(model, tokenizer, questions, max_tokens=100):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "\n",
    "    for q in questions:\n",
    "        prompt = f\"Q: {q}\\nA:\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_tokens,\n",
    "                temperature=0.3\n",
    "            )\n",
    "\n",
    "        text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "        # Remove prompt from output\n",
    "        answer = text.split(\"A:\")[-1].strip()\n",
    "        outputs.append(answer)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def compute_and_log_metrics(logger, predictions, references):\n",
    "    logger.section(\"AUTOMATIC METRICS\")\n",
    "\n",
    "    # ---------------- BLEU ----------------\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    bleu_results = bleu.compute(\n",
    "        predictions=predictions,\n",
    "        references=[[ref] for ref in references],\n",
    "        max_order=4\n",
    "    )\n",
    "\n",
    "    logger.log(f\"BLEU-4: {bleu_results['bleu']:.4f}\")\n",
    "\n",
    "    # ---------------- ROUGE ----------------\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    rouge_results = rouge.compute(\n",
    "        predictions=predictions,\n",
    "        references=references\n",
    "    )\n",
    "\n",
    "    logger.log(f\"ROUGE-L: {rouge_results['rougeL']:.4f}\")\n",
    "\n",
    "    # ---------------- BERTScore ----------------\n",
    "    P, R, F1 = score(\n",
    "        predictions,\n",
    "        references,\n",
    "        lang=\"en\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    logger.log(f\"BERTScore F1: {F1.mean().item():.4f}\")\n",
    "\n",
    "# validation data\n",
    "questions = [q for q in test_dataset['question']]\n",
    "references = [a for a in test_dataset['answer']]\n",
    "predictions = generate_answers(model, tokenizer, questions)\n",
    "\n",
    "# Log sample outputs\n",
    "logger.section(\"VALIDATION OUTPUTS\")\n",
    "for q, pred in zip(questions[:5], predictions[:5]):\n",
    "    logger.log(f\"Q: {q}\")\n",
    "    logger.log(f\"A: {pred}\")\n",
    "    logger.log(\"-\" * 40)\n",
    "\n",
    "# Log metrics\n",
    "compute_and_log_metrics(logger, predictions, references)"
   ],
   "metadata": {
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771156724941,
     "user_tz": -330,
     "elapsed": 54617,
     "user": {
      "displayName": "Atul Deshpande",
      "userId": "08542718426656085499"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a61095e0713a4d6fad71007c0ec0a786",
      "9aab365ad1304ac78cca3eda9d647dc4",
      "c471685d8c6e42c489fc8512631783ce",
      "8ebe00e757434dddabb69e1b4aae4e00",
      "650e50ddec5d455780ef5ac6c115af4b",
      "112327c3a03540b7a9faa2f8f0957ce6",
      "3a960c3b25ab46c5b4f19908fb2e9d73",
      "270553a682c14bc3920796f241825ab3",
      "b8cebdbaf5b24ad1b6f057296aebd00c",
      "0c3dee2c0cdf44828864fb26cd1299d9",
      "fa1e516505604570af181f84bb950be9",
      "24c124a4a2da41beb58445d85f5f301a",
      "4a54917ca5544f798ccaade30bed08eb",
      "71fd0096a3364f4295ea099bc5adbb1f",
      "15995f9fba72427aa9ab4661b04d7555",
      "1fc83147c6814e3096c7f6be00fc6bc7",
      "7d310223662c4e98944e23bbac75a31b",
      "7b4a0e2a42204ec79d55032a9041bf20",
      "3b640d821ad94617b2545c70fd9292ab",
      "0d328e67027d499d828fe32f7131cd02",
      "e1bf6d2620724650a0c028d85e80ff4e",
      "f6acdca126f54972992355530f0c63d1",
      "74dbd0bf5dde4c9b8719780a188f9822",
      "5fa707e0476941198200c7b223c70425",
      "bd23befcc8bd444db79973c9f443530b",
      "f85262e749ed46e3bc080193daf6bbff",
      "1c33e246538e4c489a341aaedde3dad1",
      "6237eb6c6d224205b38b521626765dfc",
      "8c95928aaea34b0b9ae7e499251b4c79",
      "2980c890b38d447f818e7f596034c2c7",
      "198ac8af597b4c8e8633c26889ec1693",
      "f6084399a19b4200a34d96caea93bb47",
      "e5c106eedec44f4c880cd5eee56ff545",
      "206bc2642cea4b01821ca5e0518b71a6",
      "536e8e3bd4fb40179697810806c689ac",
      "d5dfe635bde1480895ceee5bb5417e7f",
      "f8ca73a0d7eb408698f3f2572058b2b6",
      "52fef032b8864eb8ac2dcbb7b5f93a0a",
      "916713af9fa949bab60b94cf593e1ff1",
      "c7edd09465c34e97a0e46f71f5074ce0",
      "f807207acf8445f0b9e9f775c07c838f",
      "99c14c496cac4fbc9d08754b74903571",
      "ef90303957334e1cbe00a290dd95820e",
      "ca15f1a7c4ce4eb19f343d4b70543e28",
      "c5b08c90e6854cd1bae9b64c011acc3b",
      "6227da7d19c44a5584f474b9c44adfb0",
      "8d2ec87032ad49dd98445ec86be54b1d",
      "60862728dd5e49239aa6762bd13c2619",
      "da499ad5d5d14883b039027602b5cb0d",
      "23569bc718334ebc8a5dbf88355962da",
      "2d909dfa1fb945d49ee3edbf8aeb6c85",
      "0ae2862c01a944a3bacac12f2ea2e514",
      "4aea2104f12548c399bf14704a031a4c",
      "5689d9160b7a4acd98b7af908313c6da",
      "1c7df78604ab471485ca8c4b8945af33",
      "375d26f70ea8460b9d35ce23216c4072",
      "1e9cc6d81d8642d4bfb87e68793e1716",
      "14358d8f391b4711b665688c416fa59e",
      "06147bf3b7f94dc1a2ad915ba2e276b6",
      "db88407afbc940e8bc21c4552c5efe67",
      "d324b0f441264d55acf1af065d79dd78",
      "19144c92a60049839659e224014d570c",
      "97c43e5d7a9d47988274caeedb45da36",
      "3a0104524bb8494baf033a529f882e5d",
      "3fe32a776f304cdfbe9f720756b5b0fe",
      "3996285fe5464535bec025c34fc296e7",
      "e3f965a9b1b947419bd5787af264f24d",
      "1ad8016e346e476a8dc5e588a1e40dd1",
      "88a814cdc80643b7a6c867885e666b9d",
      "2a13fad01f0f4a619bb11a7d45ebcc0e",
      "e86b72ad70804785b3c47c3b5f62318d",
      "acf6350d6447408289249bbf7bdda455",
      "2d84602a30134438b3738f4be3c71a55",
      "7f39aa8559c645909c858622ea04f46e",
      "eb4e98f9e065443980fad72949ce95f3",
      "9f507f0af3c2400da24d924725374f84",
      "cf4883c260bc41d483608978907dce81",
      "287e0c49acbc491986612f270d441ccf",
      "2837d94cbd7e4681894e5edd288b72d0",
      "66df1fbd722d44e2b26b944fce9fe637",
      "c68a1db16af44155a7f9d3bde7d16394",
      "7df606498626455dacc52cbb06eb8130",
      "4a1cd1a586104258b061df1dcab36261",
      "3e51e0fe50214aa8a765efad462fd4a0",
      "deb86acb28d44cd59e8d3644e8453481",
      "0ed0b0686dc04681a66f318d1ec5bbd3",
      "a8dcc35d281e4f0f8267c635b2dd3d8a",
      "6b0c00bc27fd4de9beb9c03400ce6c9f",
      "b426ea7f47314d8a8211852c456eb894",
      "ab8f1decb81f4e4fa8843cd430a6b5cb",
      "bda2a3a8fffe4941b6b3e3b977927edf",
      "07bc036a96e04369a5ec5fc3e0b0542f",
      "6eec80e021f44854ae23a76c71682a1c",
      "fa66deec35ac45eaafd3a299eaa55165",
      "10a2f156e662443cbd30b316f7b2423b",
      "4903544e3c86419c864393100940fc3a",
      "11abacadb755492ebe34422cde255a3c",
      "8fb6df7068dd4f5ebbbb974078972d15",
      "c02267c05b77423eb7dba8640fe4751c",
      "f52fbffe2085494594ba68d8542e1aa8",
      "18c6add593e5423d81ff20f07c12a857",
      "635f5e6357e04effb697319051ea9593",
      "832fd684db6b47fb9f5a5444bbfe0721",
      "79dbf9ed981c4453bc9d7ccc3469c754",
      "02e367ec4f6a449db0ef5eb3a16f8d2b",
      "c056c0a21ed647fcbcf4ab18ad96157e",
      "6dd5cd524c8a4793aec5af8c56e932c1",
      "153d23f33c074a9e83fe2ad1f6fe3b79",
      "83cb949bd83a43f2b7bc7deeb9de9e8b",
      "bd914c6230734f6797c5258fde2b8712",
      "ee08d096875e4bb1b5292d2faed8e973",
      "b0b2f7d162d7423cb6986aec6a950c70",
      "cf269d5e45064badb1ef8a232d5a523d",
      "e7232dc07ef54ea8b5aeacf32e3c413f",
      "323b27c05e924bfea993d95919bfcd7e",
      "9f7a0bae383d403aba0a77f2694fe100",
      "2223dd8f70ac4bd1ac3344d34798a4a7",
      "c17e15ff9b4d45d9b7cecd81d16f2883",
      "d0a0ccc65e504c8e818b33714cabb817",
      "6301ac8f6bec46769fa4f53c69e24197",
      "57036184f7654ef88a4759ac10b38166"
     ]
    },
    "outputId": "d80fc51a-5450-432a-95c4-45754f58be92",
    "id": "if_MlM1ZHqVr"
   },
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a61095e0713a4d6fad71007c0ec0a786"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24c124a4a2da41beb58445d85f5f301a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74dbd0bf5dde4c9b8719780a188f9822"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "206bc2642cea4b01821ca5e0518b71a6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5b08c90e6854cd1bae9b64c011acc3b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "375d26f70ea8460b9d35ce23216c4072"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3f965a9b1b947419bd5787af264f24d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "287e0c49acbc491986612f270d441ccf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b426ea7f47314d8a8211852c456eb894"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f52fbffe2085494594ba68d8542e1aa8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/389 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee08d096875e4bb1b5292d2faed8e973"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "RobertaModel LOAD REPORT from: roberta-large\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ]
  }
 ]
}