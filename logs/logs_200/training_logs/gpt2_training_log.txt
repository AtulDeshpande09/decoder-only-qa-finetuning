Step 1 | loss: 4.2221
Step 1 | grad_norm: 0.8215928673744202
Step 1 | learning_rate: 0.0001
Step 1 | epoch: 0.011111111111111112
Step 10 | loss: 4.0839
Step 10 | grad_norm: 1.0864005088806152
Step 10 | learning_rate: 9.666666666666667e-05
Step 10 | epoch: 0.1111111111111111
Step 20 | loss: 3.7854
Step 20 | grad_norm: 0.7645605206489563
Step 20 | learning_rate: 9.296296296296296e-05
Step 20 | epoch: 0.2222222222222222
Step 30 | loss: 3.5842
Step 30 | grad_norm: 1.2239598035812378
Step 30 | learning_rate: 8.925925925925926e-05
Step 30 | epoch: 0.3333333333333333
Step 40 | loss: 3.3646
Step 40 | grad_norm: 1.1245876550674438
Step 40 | learning_rate: 8.555555555555556e-05
Step 40 | epoch: 0.4444444444444444
Step 50 | loss: 4.0408
Step 50 | grad_norm: 0.9936841130256653
Step 50 | learning_rate: 8.185185185185186e-05
Step 50 | epoch: 0.5555555555555556
Step 60 | loss: 3.6306
Step 60 | grad_norm: 1.205355167388916
Step 60 | learning_rate: 7.814814814814815e-05
Step 60 | epoch: 0.6666666666666666
Step 70 | loss: 3.4626
Step 70 | grad_norm: 1.0171531438827515
Step 70 | learning_rate: 7.444444444444444e-05
Step 70 | epoch: 0.7777777777777778
Step 80 | loss: 2.6539
Step 80 | grad_norm: 1.201641321182251
Step 80 | learning_rate: 7.074074074074074e-05
Step 80 | epoch: 0.8888888888888888
Step 90 | loss: 3.3762
Step 90 | grad_norm: 1.108102798461914
Step 90 | learning_rate: 6.703703703703704e-05
Step 90 | epoch: 1.0
Step 100 | loss: 2.9635
Step 100 | grad_norm: 1.2089074850082397
Step 100 | learning_rate: 6.333333333333333e-05
Step 100 | epoch: 1.1111111111111112
Step 110 | loss: 3.2157
Step 110 | grad_norm: 1.3215992450714111
Step 110 | learning_rate: 5.962962962962964e-05
Step 110 | epoch: 1.2222222222222223
Step 120 | loss: 3.5841
Step 120 | grad_norm: 1.5803587436676025
Step 120 | learning_rate: 5.592592592592593e-05
Step 120 | epoch: 1.3333333333333333
Step 130 | loss: 3.4301
Step 130 | grad_norm: 1.3477274179458618
Step 130 | learning_rate: 5.222222222222223e-05
Step 130 | epoch: 1.4444444444444444
Step 140 | loss: 2.9944
Step 140 | grad_norm: 1.4336947202682495
Step 140 | learning_rate: 4.851851851851852e-05
Step 140 | epoch: 1.5555555555555556
Step 150 | loss: 3.7591
Step 150 | grad_norm: 2.09378719329834
Step 150 | learning_rate: 4.481481481481482e-05
Step 150 | epoch: 1.6666666666666665
Step 160 | loss: 3.2198
Step 160 | grad_norm: 2.182729721069336
Step 160 | learning_rate: 4.111111111111111e-05
Step 160 | epoch: 1.7777777777777777
Step 170 | loss: 3.609
Step 170 | grad_norm: 2.027505874633789
Step 170 | learning_rate: 3.740740740740741e-05
Step 170 | epoch: 1.8888888888888888
Step 180 | loss: 2.9189
Step 180 | grad_norm: 1.9490066766738892
Step 180 | learning_rate: 3.3703703703703706e-05
Step 180 | epoch: 2.0
Step 190 | loss: 2.7806
Step 190 | grad_norm: 2.6293599605560303
Step 190 | learning_rate: 3e-05
Step 190 | epoch: 2.111111111111111
Step 200 | loss: 2.5618
Step 200 | grad_norm: 1.639744758605957
Step 200 | learning_rate: 2.6296296296296296e-05
Step 200 | epoch: 2.2222222222222223
Step 210 | loss: 3.8696
Step 210 | grad_norm: 1.7140603065490723
Step 210 | learning_rate: 2.2592592592592594e-05
Step 210 | epoch: 2.3333333333333335
Step 220 | loss: 2.773
Step 220 | grad_norm: 1.7696179151535034
Step 220 | learning_rate: 1.888888888888889e-05
Step 220 | epoch: 2.4444444444444446
Step 230 | loss: 3.2443
Step 230 | grad_norm: 2.025507926940918
Step 230 | learning_rate: 1.5185185185185186e-05
Step 230 | epoch: 2.5555555555555554
Step 240 | loss: 3.0858
Step 240 | grad_norm: 1.488105297088623
Step 240 | learning_rate: 1.1481481481481482e-05
Step 240 | epoch: 2.6666666666666665
Step 250 | loss: 3.587
Step 250 | grad_norm: 3.085805654525757
Step 250 | learning_rate: 7.777777777777777e-06
Step 250 | epoch: 2.7777777777777777
Step 260 | loss: 3.6641
Step 260 | grad_norm: 1.4282522201538086
Step 260 | learning_rate: 4.074074074074075e-06
Step 260 | epoch: 2.888888888888889
Step 270 | loss: 2.6648
Step 270 | grad_norm: 1.6734437942504883
Step 270 | learning_rate: 3.703703703703704e-07
Step 270 | epoch: 3.0
Step 270 | train_runtime: 30.9694
Step 270 | train_samples_per_second: 17.437
Step 270 | train_steps_per_second: 8.718
Step 270 | total_flos: 11999655419904.0
Step 270 | train_loss: 3.4769845123644227
Step 270 | epoch: 3.0
