Step 10 | loss: 2.3475
Step 10 | grad_norm: 1.1722966432571411
Step 10 | learning_rate: 8.695652173913044e-05
Step 10 | epoch: 0.4444444444444444
Step 20 | loss: 2.0304
Step 20 | grad_norm: 0.7223120927810669
Step 20 | learning_rate: 7.246376811594203e-05
Step 20 | epoch: 0.8888888888888888
Step 30 | loss: 1.8545
Step 30 | grad_norm: 0.9826650619506836
Step 30 | learning_rate: 5.797101449275363e-05
Step 30 | epoch: 1.3111111111111111
Step 40 | loss: 1.6609
Step 40 | grad_norm: 0.8422233462333679
Step 40 | learning_rate: 4.347826086956522e-05
Step 40 | epoch: 1.7555555555555555
Step 50 | loss: 1.5996
Step 50 | grad_norm: 1.2303712368011475
Step 50 | learning_rate: 2.8985507246376814e-05
Step 50 | epoch: 2.1777777777777776
Step 60 | loss: 1.5517
Step 60 | grad_norm: 0.9967731237411499
Step 60 | learning_rate: 1.4492753623188407e-05
Step 60 | epoch: 2.6222222222222222
Step 69 | train_runtime: 182.1161
Step 69 | train_samples_per_second: 2.965
Step 69 | train_steps_per_second: 0.379
Step 69 | total_flos: 373110742794240.0
Step 69 | train_loss: 1.8038072309632232
Step 69 | epoch: 3.0